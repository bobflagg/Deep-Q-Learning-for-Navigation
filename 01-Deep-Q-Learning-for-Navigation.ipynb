{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Deep Q-Learning for Navigation\n",
    "---\n",
    "\n",
    "In this notebook I will solve the [Unity ML Banana-Collector environment](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Learning-Environment-Examples.md#banana-collector) using Deep Q-Learning as described in [Human-level control through deep reinforcement learning](https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf).  In follow up notebooks I'll improve on this solution.  See the [README](https://github.com/bobflagg/Deep-Q-Learning-for-Navigation/blob/master/README.md) for instructions on how to setup your environment to run the code here.\n",
    "\n",
    "The goal of the Navigation Project is to train an agent to navigate (and collect bananas!) in a large, square world.\n",
    "A reward of +1 is provided for collecting a yellow banana, and a reward of -1 is provided for collecting a blue banana. Thus, the goal of the agent is to collect as many yellow bananas as possible while avoiding blue bananas.\n",
    "\n",
    "The state space has 37 dimensions and contains the agent's velocity, along with ray-based perception of objects around the agent's forward direction. Given this information, the agent has to learn how to best select actions. Four discrete actions are available, corresponding to:\n",
    "\n",
    "- [**0**] move forward.\n",
    "- [**1**] move backward.\n",
    "- [**2**] turn left.\n",
    "- [**3**] turn right.\n",
    "\n",
    "The task is episodic, and in order to solve the environment, the agent must get an average score of +13 over 100 consecutive episodes.\n",
    "\n",
    "\n",
    "## Background\n",
    "\n",
    "\n",
    "The [Unity ML Banana-Collector](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Learning-Environment-Examples.md#banana-collector) is a *sequential decision making problem*, in which an agent interacts with an environment over discrete time steps and tries to find a policy to maximize the expected discounted return:\n",
    "$$G_t = \\sum_{\\tau=t}^{\\infty}\\gamma^{\\tau-t}R_\\tau,$$\n",
    "where $\\gamma\\in [0, 1]$ is a discount factor that trades-off the importance of immediate and future rewards. See [Sutton and Barto](http://incompleteideas.net/book/the-book.html) for a general discussion of this sort of problem.\n",
    "\n",
    "In these notebooks I'll focus on a particular class of algorithms for \n",
    "solving sequential decision making problems called **Q-learning**. The main idea behind Q-Learning is that if we had a function \n",
    "$$Q^*:{\\cal S} \\times {\\cal A}:\\to\\mathbb{R},$$\n",
    "where ${\\cal S}$ is the set of states and ${\\cal A}$ is the set of possible actions, that could tell us what our return would be, if we were to take an action in a given state, then we could easily construct a policy that maximizes our rewards:\n",
    "$$\\pi^*(s) = \\operatorname{arg\\,max}_{a} Q^*(s,a).$$\n",
    "Unfortunately we don't know enough about the environment to compute $Q^*(s,a)$. One approach to overcome this problem is [Q-learning](http://www.cs.rhul.ac.uk/~chrisw/new_thesis.pdf), \n",
    "an early breakthrough in reinforcement learning.   Q-learning approximates the optimal action-value function with a learned action-value function $Q(s,a)$, which \n",
    "is initialized randomly and then updated incrementally according to the formula\n",
    "$$Q(S_t,A_t) \\leftarrow (1-\\alpha)\\cdot Q(S_t,A_t) + \\alpha \\cdot \\big[R_{t+1}+\\gamma \\cdot \\max_a Q(S_{t+1},a)\\big].$$\n",
    "In the standard Q-learning implementation Q-values are stored in a table.\n",
    "One cell is required per combination of state and action. This implementation\n",
    "is not amenable to continuous state problems like the Unity ML-Agent Banana Collector.\n",
    "The simplest way to get around this is to apply discretization but that scales poorly: as the number of\n",
    "state and action variables increase, the size of the table used to store Q-values\n",
    "grows exponentially. The next section describes an alternative to discretized Q-learning, which scales well.\n",
    "\n",
    "## Deep Q-Learning\n",
    "\n",
    "<img src=\"doc/images/dqn.png\" alt=\"Deep Q-Network\" style=\"margin-left: 140px;; margin-right: 100px;\" />\n",
    "     \n",
    "Deep Q-learning is an alternative to discretized Q-learning, which addresses the scaling problem by approximating $Q^*(s,a)$ \n",
    "with a *deep Q-network*, $Q(s,a|\\theta)$, and tuning the parameters by optimizing the following\n",
    "of loss function:\n",
    "$$L(\\theta) = \\mathbb{E}\\big[\\big(y^{DQN}-Q(S_t, A_t|\\theta)\\big)^2\\big],$$\n",
    "with \n",
    "$$ y^{DQN}=R_t+\\gamma\\cdot\\max_{a'}Q(S_{t+1},a'|\\theta^-),$$\n",
    "where $\\theta^-$ representes the parameters of a fixed and separate *target network*. Another key innovation of deep Q-learning is the use of a *replay buffer* which stores experience tuples while interacting with the environment for sampling later in training the neural network.  This device eliminates unwanted correlation between consecutive states in an episode.\n",
    "\n",
    "## Q-Network\n",
    "\n",
    "The implementation for my Q-network is taken directly from the [course solution](https://github.com/udacity/deep-reinforcement-learning/tree/master/dqn/solution) to the [Deep Q-Learning Coding Exercise](https://github.com/udacity/deep-reinforcement-learning/tree/master/dqn).  It has three fully connected linear layers with [ReLu](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)) activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed=0, fc1_units=64, fc2_units=64):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fc1_units (int): Number of nodes in first hidden layer\n",
    "            fc2_units (int): Number of nodes in second hidden layer\n",
    "        \"\"\"\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build a network that maps state -> action values.\"\"\"\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Q-Learning Agent\n",
    "\n",
    "My code for a [deep Q-learning agent](https://github.com/bobflagg/Deep-Q-Learning-for-Navigation/blob/master/dqn_agent.py) is also taken directly from the [course solution](https://github.com/udacity/deep-reinforcement-learning/tree/master/dqn/solution) to the [Deep Q-Learning Coding Exercise].\n",
    "\n",
    "The behavior of this agent depends on several hyperparameters, including: \n",
    "\n",
    "- BATCH_SIZE = the size of batches used when updating parameters via gradient descent;\n",
    "- BUFFER_SIZE = the number of samples to store in the replay buffer for later sampling;\n",
    "- GAMMA = a real number in [0,1] that sets the trade-off in the importance of immediate and future rewards;\n",
    "- LR = the coefficient applied to the gradient vector is a gradient update step;\n",
    "- TAU = the weight applied to the target parameters in the soft update of the local network parameters; and\n",
    "- UPDATE_EVER = how often to run the soft update of the local network parameters.\n",
    "\n",
    "Initially, I'll take values for these hyperparameters suggested in the course example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = int(1e5)\n",
    "BATCH_SIZE = 64\n",
    "GAMMA = 0.99\n",
    "TAU = 1e-3\n",
    "LR = 5e-4\n",
    "UPDATE_EVERY = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The replay buffer which stores experience tuples while interacting with the environment for sampling later in training the neural network can be implemented as a simple queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, deque\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            action_size (int): dimension of each action\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)  \n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "  \n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My code for the [DQN-Agent](https://github.com/bobflagg/Deep-Q-Learning-for-Navigation/blob/master/dqn_agent.py) is also taken directly from the [course solution](https://github.com/udacity/deep-reinforcement-learning/tree/master/dqn/solution) to the [Deep Q-Learning Coding Exercise](https://github.com/udacity/deep-reinforcement-learning/tree/master/dqn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Agent():\n",
    "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed):\n",
    "        \"\"\"Initialize an Agent object.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): dimension of each state\n",
    "            action_size (int): dimension of each action\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(seed)\n",
    "\n",
    "        # Q-Network\n",
    "        self.qnetwork_local = QNetwork(state_size, action_size, seed).to(device)\n",
    "        self.qnetwork_target = QNetwork(state_size, action_size, seed).to(device)\n",
    "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=LR)\n",
    "\n",
    "        # Replay memory\n",
    "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, seed)\n",
    "        # Initialize time step (for updating every UPDATE_EVERY steps)\n",
    "        self.t_step = 0\n",
    "    \n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        # Save experience in replay memory\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "        \n",
    "        # Learn every UPDATE_EVERY time steps.\n",
    "        self.t_step = (self.t_step + 1) % UPDATE_EVERY\n",
    "        if self.t_step == 0:\n",
    "            # If enough samples are available in memory, get random subset and learn\n",
    "            if len(self.memory) > BATCH_SIZE:\n",
    "                experiences = self.memory.sample()\n",
    "                self.learn(experiences, GAMMA)\n",
    "\n",
    "    def act(self, state, eps=0.0):\n",
    "        \"\"\"Returns actions for given state as per current policy.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state (array_like): current state\n",
    "            eps (float): epsilon, for epsilon-greedy action selection\n",
    "        \"\"\"\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        self.qnetwork_local.eval()\n",
    "        with torch.no_grad(): action_values = self.qnetwork_local(state)\n",
    "        self.qnetwork_local.train()\n",
    "\n",
    "        # Epsilon-greedy action selection\n",
    "        if random.random() > eps: return np.argmax(action_values.cpu().data.numpy())\n",
    "        else: return random.choice(np.arange(self.action_size))\n",
    "\n",
    "    def learn(self, experiences, gamma):\n",
    "        \"\"\"Update value parameters using given batch of experience tuples.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            experiences (Tuple[torch.Tensor]): tuple of (s, a, r, s', done) tuples \n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        # Get max predicted Q values (for next states) from target model\n",
    "        Q_targets_next = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "        # Compute Q targets for current states \n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "\n",
    "        # Get expected Q values from local model\n",
    "        Q_expected = self.qnetwork_local(states).gather(1, actions)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        # Minimize the loss\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # ------------------- update target network ------------------- #\n",
    "        self.soft_update(self.qnetwork_local, self.qnetwork_target, TAU)                     \n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            local_model (PyTorch model): weights will be copied from\n",
    "            target_model (PyTorch model): weights will be copied to\n",
    "            tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "I'll make a small change to the implementation provided in the [course solution](https://github.com/udacity/deep-reinforcement-learning/tree/master/dqn/solution) to the [Deep Q-Learning Coding Exercise](https://github.com/udacity/deep-reinforcement-learning/tree/master/dqn) by adding code to plot scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "def train(env, agent, n_episodes=2000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    # get the default brain\n",
    "    brain_name = env.brain_names[0]\n",
    "    #brain = env.brains[brain_name]\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        state = env_info.vector_observations[0] \n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state, eps)\n",
    "            env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "            next_state = env_info.vector_observations[0]   # get the next state\n",
    "            reward = env_info.rewards[0]                   # get the reward\n",
    "            done = env_info.local_done[0]                  # see if episode has finished\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done: break \n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=13.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "            break\n",
    "    # plot the scores\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.plot(np.arange(len(scores)), scores)\n",
    "    plt.axhline(y=13, color='r', linestyle='-')\n",
    "    plt.ylabel('Score')\n",
    "    plt.xlabel('Episode #')\n",
    "    plt.show()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm finally ready to train a deep Q-learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 0.51\n",
      "Episode 200\tAverage Score: 3.57\n",
      "Episode 300\tAverage Score: 7.84\n",
      "Episode 400\tAverage Score: 8.63\n",
      "Episode 500\tAverage Score: 12.72\n",
      "Episode 506\tAverage Score: 13.01\n",
      "Environment solved in 406 episodes!\tAverage Score: 13.01\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 29s, sys: 23.3 s, total: 3min 52s\n",
      "Wall time: 7min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "env = UnityEnvironment(file_name=\"./data/Banana.app\")\n",
    "\n",
    "agent = Agent(state_size=37, action_size=4, seed=0)\n",
    "scores = train(env, agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the [Unity ML Banana-Collector environment](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Learning-Environment-Examples.md#banana-collector)\n",
    "was solved in about 400 episodes! Not bad at all.  \n",
    "\n",
    "I'll save the weights of the local network of this successful agent to the file dqn-model-weights.pth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(agent.qnetwork_local.state_dict(), 'dqn-model-weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's reload the local network weights and see how the network fairs in yellow banana collecting. \n",
    "\n",
    "**Note:** To get the cell below to work I had to restart the kernel and run all the cells above except the training cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "handle is closed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-49a7249b225c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnityEnvironment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./data/Banana.app\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0menv_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_observations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_name, worker_id, base_port, curriculum, seed, docker_training, no_graphics)\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0maca_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_academy_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrl_init_parameters_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnityTimeOutException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36msend_academy_parameters\u001b[0;34m(self, init_parameters)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnityInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrl_initialization_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrl_initialization_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrap_unity_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrl_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnityRLInput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnityOutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/rpc_communicator.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0;34m\"You may need to manually close a previously opened environment \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \"or use a different worker number.\".format(str(self.worker_id)))\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             raise UnityTimeOutException(\n\u001b[1;32m     60\u001b[0m                 \u001b[0;34m\"The Unity environment took too long to respond. Make sure that :\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;34m\"\"\"Whether there is any input available to be read\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_check_closed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"handle is closed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: handle is closed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception calling application: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rflagg/anaconda3/envs/drlnd/lib/python3.6/site-packages/grpc/_server.py\", line 385, in _call_behavior\n",
      "    return behavior(argument, context), True\n",
      "  File \"/Users/rflagg/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/rpc_communicator.py\", line 25, in Exchange\n",
      "    self.child_conn.send(request)\n",
      "  File \"/Users/rflagg/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/Users/rflagg/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/rflagg/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from unityagents import UnityEnvironment\n",
    "\n",
    "network = QNetwork(state_size=37, action_size=4, seed=0)\n",
    "network.load_state_dict(torch.load('dqn-model-weights.pth'))\n",
    "network.eval()\n",
    "\n",
    "def act(network, state):\n",
    "    state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "    with torch.no_grad(): action_values = network(state)\n",
    "    return np.argmax(action_values.cpu().data.numpy())\n",
    "\n",
    "env = UnityEnvironment(file_name=\"./data/Banana.app\")\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "state = env_info.vector_observations[0]\n",
    "score = 0.0\n",
    "\n",
    "for step in tqdm(range(1000)):\n",
    "    action = act(network, state)\n",
    "    env_info = env.step(action)[brain_name]\n",
    "    next_state = env_info.vector_observations[0]\n",
    "    reward = env_info.rewards[0]\n",
    "    done = env_info.local_done[0]\n",
    "    score += reward\n",
    "    state = next_state\n",
    "    if done: break\n",
    "    \n",
    "    \n",
    "print(\"Average Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
